# ğŸš€ Pipeline Optimiser

<div align="center">

**An AI-powered CI/CD pipeline optimisation system that automatically analyses GitHub Actions workflows, identifies performance bottlenecks, and generates optimised configurations.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL 14+](https://img.shields.io/badge/postgresql-14+-blue.svg)](https://www.postgresql.org/)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Database Design](#-database-design)
- [Setup](#-setup)
- [Design Patterns](#-design-patterns)
- [License](#-license)
- [Acknowledgments](#-acknowledgments)

---

## ğŸ¯ Overview

Pipeline Optimiser uses Claude AI to intelligently analyse your CI/CD pipelines and suggest improvements for:

- ğŸ“¦ **Missing dependency caching** (npm, pip, Maven, Docker layers)
- âš¡ **Parallelisation opportunities** (removing unnecessary job dependencies)
- ğŸ”„ **Redundant steps** and inefficient configurations
- ğŸ”’ **Security vulnerabilities**

The system follows a multi-agent architecture where specialised agents collaborate to analyse, optimise, review, and optionally create pull requests with fixes.

---

## ğŸ—ï¸ Architecture

### ğŸ“ Detailed Design

<div align="center">
<img alt="Detailed Architecture Design" src="https://github.com/user-attachments/assets/3c816b33-1d59-4a17-b794-db4b41605980" />
</div>

---
### â˜ï¸ Hosting Design

<div align="center">
<img alt="Hosting Architecture Design" src="https://github.com/user-attachments/assets/06874466-4df2-44ef-8417-8160a538fb26" />
</div>

### ğŸ§© Core Components

#### **Agents/Tools:**

- **ğŸ” Ingestor** - Fetches pipeline YAML and build logs from GitHub
- **ğŸ·ï¸ Classifier** - Determines workflow type (CI/CD/Both) and risk level (LOW/MEDIUM/HIGH)
- **ğŸ§­ Decision** - LLM based routing, decides which agents to run based on context
- **âœ… Validator** - Validates pipeline syntax and structure (Mode = input/output for pre and post validation)
- **âš™ï¸ Optimiser** - Two-stage analysis and LLM based optimisation
- **ğŸ­ Critic** - Reviews proposed changes for safety and quality
- **âš ï¸ Risk Assessment** - Scores the risk of applying changes
- **ğŸ”’ Security Scanner** - Detects security issues in pipelines
- **ğŸ”§ Resolver** - Creates GitHub pull requests with optimised YAML

#### **ğŸ“ Plan & Execution Logic:**

The Classifier classifies the pipeline based on the risk profile and generates an execution plan:

| Risk Profile | Execution Flow |
|--------------|----------------|
| **High** | Validate â†’ Optimise â†’ Post Validate â†’ Critic â†’ Risk Assess â†’ Security Scan â†’ Resolve |
| **Medium** | Validate â†’ Optimise â†’ Post Validate â†’ Critic â†’ Security Scan â†’ Resolve |
| **Low** | Validate â†’ Optimise â†’ Post Validate â†’ Critic â†’ Resolve |

#### **ğŸ¯ Decision Logic:**

- âœ“ Validation must pass before optimisation
- âœ“ Critic only runs if optimised YAML exists
- âœ“ Risk assessment skipped for LOW risk workflows
- âœ“ PR creation requires critic confidence >= 0.5

---

## ğŸ—„ï¸ Database Design

### Schema Overview

#### **Core Tables:**

- **`repositories`** - Repository metadata and tracking
- **`runs`** - Optimisation execution records with correlation IDs
- **`issues`** - Detected pipeline problems (type, severity, location, fix)
- **`decisions`** - Agent execution decisions (which tools ran and why)
- **`reviews`** - Critic, risk, and security assessment results
- **`artifacts`** - Generated YAML and intermediate analysis data
- **`prs`** - Pull request tracking (URL, status, merge state)

#### **Relationships:**

```
repositories (1) â”€â”€> (N) runs
runs (1) â”€â”€> (N) issues
runs (1) â”€â”€> (N) decisions
runs (1) â”€â”€> (N) reviews
runs (1) â”€â”€> (N) artifacts
runs (1) â”€â”€> (1) prs
```

> ğŸ“„ **See** `app/repository/sql/create.sql` for complete schema definition.

---

## ğŸ› ï¸ Setup

### Prerequisites

- ğŸ Python 3.11+
- ğŸ˜ PostgreSQL 14+
- ğŸ¤– Anthropic API key
- ğŸ”‘ GitHub Personal Access Token
- ğŸ› ï¸ Make

### Installation

#### **1. Clone and configure:**

```bash
git clone https://github.com/yourusername/pipeline-optimiser.git
cd pipeline-optimiser
cp .env-example .env
# Edit .env with your API keys
```

#### **2. Setup everything using Make:**

```bash
# Install dependencies and setup database
make setup

# Start the API server
make run

# Run unit tests
make test-all
make test-components

# Run sample tests (actual llm call)
# Edit the app/tests/pipeline_test.py with your test repo, pipeline_path
# Run the below make command to test few sample requests making actual llm call
make optimise
```

---

## ğŸ§© Design Patterns

This section outlines the core software design patterns implemented in the **Pipeline Optimiser**, ensuring scalability, maintainability, and clean separation of concerns.

---

### âš™ï¸ Application Design Patterns

#### ğŸ—‚ï¸ Repository Pattern

All database operations are abstracted through the `PipelineRepository` class.

This separates **business logic** from **data persistence**, making testing easier and allowing database layer changes without impacting the application logic.

> **âœ¨ Benefit:** Enables a clean separation of concerns and flexible database implementations.

---

#### ğŸ” Singleton Pattern

The database connection pool is implemented as a **singleton**, ensuring all components reuse the same connection instance.

This prevents connection exhaustion and optimizes resource management.

> **âœ¨ Benefit:** Efficient connection reuse with centralized and controlled resource management.

---

#### ğŸ­ Facade Pattern

The `LLMClient` serves as a **facade** for the Anthropic API, providing a simplified interface that hides low-level complexity.

This centralizes error handling and makes it easy to switch between LLM providers.

> **âœ¨ Benefit:** Simplified API usage with centralized error handling and flexible provider integration.

---

#### ğŸ§± Template Pattern

The `BaseService` class defines a **common execution flow**â€”including logging, validation, and error handlingâ€”while subclasses implement their specific `_execute()` logic.

This ensures consistency across all agent services.

> **âœ¨ Benefit:** Consistent execution flow with reusable logging and error handling.

---

#### ğŸ§© Dependency Injection

Dependencies (e.g., `LLMClient`, `PipelineRepository`) are injected through constructors, enabling components to operate independently of specific implementations.

This improves testability and supports flexible configuration.

> **âœ¨ Benefit:** Loose coupling and easy unit testing using mocks or alternate implementations.

---

#### ğŸ‘ï¸ Observer Pattern

A **correlation ID** is propagated through all components, ensuring each log entry and database operation can be traced back to the original request.

This enables distributed tracing and full visibility across the pipeline.

> **âœ¨ Benefit:** End-to-end traceability for debugging, auditing, and monitoring.

---

### ğŸ¤– Agent Design Patterns

#### ğŸ§­ Planâ€“Execute Pattern

The agent pipeline follows a sequential **planâ€“execute flow**, where each stage processes input and passes results downstream:

`Ingestor â†’ Classifier â†’ Decision â†’ Validator â†’ Optimiser â†’ Critic â†’ Resolver`

The **Decision Agent** dynamically routes requests based on contextual rules.

> **âœ¨ Benefit:** Flexible, loosely coupled agent interactions with dynamic routing.

---

#### âš–ï¸ Two-Phase Commit Pattern

The Optimiser runs in two distinct stages:

1. **Analysis Phase** â€“ Identifies issues and determines required changes.
2. **Execution Phase** â€“ Applies the fixes safely and reliably.

This structure supports rollback and improves reliability.

> **âœ¨ Benefit:** Safe, reversible changes with clear separation of analysis and execution.

---

#### ğŸ§  Critic Pattern

The **Critic Agent** reviews all Optimiser-generated YAML configurations for safety, quality, and correctness before they are merged.

It acts as a **quality gate**, assigning confidence scores and blocking unsafe updates.

> **âœ¨ Benefit:** Ensures output integrity, prevents unsafe changes, and supports automated decision-making.

---

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE for details.

---

## ğŸ™ Acknowledgments

**Questions or Issues?** Open an issue on GitHub.

---

<div align="center">
</div>
